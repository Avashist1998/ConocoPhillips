{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.companieshistory.com/wp-content/uploads/2013/07/ConocoPhillips.png\"\n",
    "     alt=\"Markdown Monster icon\"\n",
    "     style=\"float: left; margin-right: 5px;\" />\n",
    "\n",
    "# Detection before failure \n",
    "\n",
    "**Abhay Vashist, Adam Johnston, Rajan Kapoor, Yung-Hsin Tung**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### The Challenge\n",
    "**The goal of this challenge will be to predict surface and down-hole failures using the data set provided. This information can be used to send crews out to a well location to fix equipment on the surface or send a workover rig to the well to pull down-hole equipment and address the failure.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sns \n",
    "from sklearn import preprocessing\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "# we will have to play with the error to figure out which meter is best to train the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the data\n",
    "test_df = pd.read_csv('equipfails/equip_failures_test_set.csv')\n",
    "train_df = pd.read_csv('equipfails/equip_failures_training_set.csv')\n",
    "test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace string `'na'` with `np.nan`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.replace('na', np.nan)\n",
    "train_df_na = (train_df.isnull().sum()/len(train_df))*100\n",
    "train_df_na = train_df_na.drop(train_df_na[train_df_na == 0].index).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get an idea of how the missing values are characterized, we sum the number in each column and divide by the number of rows to get the percentage of missing values for each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_df_na = pd.DataFrame(train_df_na)\n",
    "train_df_na.columns = ['Percentage of NAN values']\n",
    "plt.scatter(x = train_df_na.index, y = train_df_na['Percentage of NAN values'])\n",
    "plt.legend(train_df_na.columns), plt.ylabel('Percentage of missing data')\n",
    "plt.xlabel('feature id'), plt.title('Missing Value Characterization')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above plot, we see three distinct clusters that we have marked in the plot below. We identified these three possible threshold values that can be used to remove the columns from the data set (shown below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x = train_df_na.index, y = train_df_na['Percentage of NAN values'])\n",
    "plt.ylabel('Percentage of missing data')\n",
    "plt.xlabel('feature name'), plt.title('Missing Value Characterization')\n",
    "xs = np.linspace(1,len(train_df_na['Percentage of NAN values'])+1,len(train_df_na['Percentage of NAN values'])+1)\n",
    "horiz_line_data = np.array([30 for i in range(len(xs))])\n",
    "plt.plot(xs, horiz_line_data, 'b--') \n",
    "horiz_line_data = np.array([40 for i in range(len(xs))])\n",
    "plt.plot(xs, horiz_line_data, 'r--') \n",
    "horiz_line_data = np.array([60 for i in range(len(xs))])\n",
    "plt.plot(xs, horiz_line_data, 'k--') \n",
    "plt.legend(['greater > 60','greater > 40' ,'greater > 30', (train_df_na.columns)[0]], loc  = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our main focus in pre-processing is to handle the missing values. There are two tuneable parameters for this process, the threshold for removing a column completely as mentioned above, and the replacement method. The threshold is the percentage of NaN values such that, if a column contains more than that threshold of NaN values, we consider the entire feature to be invalid and remove it from the dataset. The method of replacement is then used to replace the remaining NaN values. We chose to explore the following parameters using a grid search.\n",
    "\n",
    "| NaN Threshold | Replacement Method |\n",
    "|---------------|--------------------|\n",
    "| 20%           | Mean               |\n",
    "| 40%           | Median             |\n",
    "| 60%           | Mode               |\n",
    "| 100%          |                    |\n",
    "\n",
    "For defaults, we chose 40% NaN threshold and mean replacement method so that we could do model exploration and decide on the model. After chosing a model, we will be able to do the grid search to select the best pre-processing parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create pre-processing fn with defaults\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "train_df.replace('na', np.nan, inplace=True)\n",
    "scaler.fit(train_df.drop('id', axis=1).drop('target', axis=1))\n",
    "def preprocess_data(dataset, scaler, nan_thresh=0.4, replace='mean'):\n",
    "    dataset.replace('na', np.nan, inplace=True)\n",
    "    df = dataset.drop('id', axis=1)\n",
    "    ids = dataset['id']\n",
    "    X = pd.DataFrame(\n",
    "        scaler.transform(df), \n",
    "        columns=[df.columns])\n",
    "    X.insert(0, 'id', ids)\n",
    "    for column in X.columns:\n",
    "        if X[column][X[column] == np.nan].sum() > (60000 * nan_thresh):\n",
    "            X.drop(column, inplace=True)\n",
    "    if replace == 'mean':\n",
    "        X.fillna(X.mean(), inplace=True)\n",
    "    elif replace == 'median':\n",
    "        X.fillna(X.median(), inplace=True)\n",
    "    elif replace == 'mode':\n",
    "        X.fillna(X.mode(), inplace=True)\n",
    "    elif replace == 'zero':\n",
    "        X.fillna(0, inplace=True)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we assess the performance of an Support Vector Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "X = preprocess_data(train_df.drop('target', axis=1), scaler, nan_thresh=0.6, replace='zero')\n",
    "y = train_df['target']\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, test_size=0.3)\n",
    "clf = SVC(gamma='auto')\n",
    "clf.fit(train_X, train_y) \n",
    "val_predictions = clf.predict(val_X)\n",
    "val_mae = mean_absolute_error(val_predictions, val_y)\n",
    "print('SVM Acc:',1-val_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we assess the performance of a decision tree model. We used both a classifier and a regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocess_data(train_df.drop('target', axis=1), scaler, nan_thresh=0.6, replace='zero')\n",
    "y = train_df['target']\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, test_size=0.3)\n",
    "descision_tree_model = RandomForestRegressor(random_state=1)\n",
    "# Fit Model\n",
    "descision_tree_model.fit(train_X, train_y)\n",
    "\n",
    "# Make validation predictions and calculate mean absolute error\n",
    "val_predictions = descision_tree_model.predict(val_X).astype(int)\n",
    "val_mae = mean_absolute_error(val_predictions, val_y)\n",
    "print('Regressor Acc:', 1-(val_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocess_data(train_df.drop('target', axis=1), scaler, nan_thresh=0.6, replace='zero')\n",
    "y = train_df['target']\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, test_size=0.3)\n",
    "descision_tree_model = tree.DecisionTreeClassifier(random_state=1)\n",
    "# Fit Model\n",
    "descision_tree_model.fit(train_X, train_y)\n",
    "\n",
    "# Make validation predictions and calculate mean absolute error\n",
    "val_predictions = descision_tree_model.predict(val_X)\n",
    "val_mae = mean_absolute_error(val_predictions, val_y)\n",
    "print('Classifier Acc:', 1-(val_mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Decision Tree Classifier algorithm when trained over 0.8 percent of the train was able to achieve an accuracy of over 98%. The Tree performs better than SVM before any adjustment. Decision Tree algorithm only trains based on the empirical and does not try to optimize the margin between the two different classes. To take margin to take into account we implemented a Decision Tree Regressor algorithm. In theory, the regression tree algorithm provides control over the generalization error. In practice, we found that there was no difference in the error between the Classifier and Regressor. Therefore, we chose to go with a Decision Tree Classifier model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Processing Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After selecting a model, we applied a grid search on the pre-processing parameters to decide the best pre-processing method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_heatmap(grid_search_results, params, labels):\n",
    "    param1, param2 = params\n",
    "    label1, label2 = labels\n",
    "    param_index = grid_search_results['params']\n",
    "    mean_test_scores = grid_search_results['mean_test_score']\n",
    "    cv_data = {\n",
    "        param1: [],\n",
    "        param2: [],\n",
    "        'mean_test_score': []\n",
    "    }\n",
    "    for i in range(len(param_index)):\n",
    "        cv_data[param1].append(param_index[i][param1])\n",
    "        cv_data[param2].append(param_index[i][param2])\n",
    "        cv_data['mean_test_score'].append(mean_test_scores[i])\n",
    "    grid_search_results = pd.DataFrame(cv_data)\n",
    "    p1 = grid_search_results[param1].unique()\n",
    "    p2 = grid_search_results[param2].unique()\n",
    "    grid_search = np.zeros((len(p1), len(p2)))\n",
    "    for i in range(len(p1)):\n",
    "        for j in range(len(p2)):\n",
    "            grid_search[i][j] = grid_search_results[\n",
    "                (grid_search_results[param1] == p1[i]) & \n",
    "                (grid_search_results[param2] == p2[j])\n",
    "            ]['mean_test_score']\n",
    "    fig, ax = plt.subplots()\n",
    "    cax = ax.matshow(grid_search, cmap='hot')\n",
    "    fig.colorbar(cax)\n",
    "    ax.set_xticklabels(['']+[str(p) for p in p1])\n",
    "    ax.set_yticklabels(['']+[str(p) for p in p2])\n",
    "    ax.set_xlabel(label1)\n",
    "    ax.xaxis.set_label_position('top') \n",
    "    ax.set_ylabel(label2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing grid\n",
    "preproc_params = {\n",
    "    'nan_thresh': [0.2, 0.4, 0.6, 1.0],\n",
    "    'replace': ['mean', 'median', 'zero']\n",
    "}\n",
    "preproc_grid_results = {\n",
    "    'params': [],\n",
    "    'mean_test_score': []\n",
    "}\n",
    "X_preproc = np.empty((len(preproc_params['nan_thresh']), len(preproc_params['replace'])))\n",
    "for i in range(0, len(preproc_params['nan_thresh'])):\n",
    "    for j in range(0, len(preproc_params['replace'])):\n",
    "        X = preprocess_data(train_df.drop('target', axis=1), \n",
    "                            scaler, \n",
    "                            preproc_params['nan_thresh'][i],\n",
    "                            preproc_params['replace'][j])\n",
    "        y = train_df['target']\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)\n",
    "        rf = RandomForestClassifier()\n",
    "        rf.fit(X_train, y_train)\n",
    "        y_pred = rf.predict(X_test)\n",
    "        preproc_grid_results['params'].append({\n",
    "            'nan_thresh': preproc_params['nan_thresh'][i],\n",
    "            'replace': preproc_params['replace'][j]\n",
    "        })\n",
    "        preproc_grid_results['mean_test_score'].append(metrics.accuracy_score(y_test, y_pred))\n",
    "grid_search_heatmap(preproc_grid_results, ['nan_thresh', 'replace'], ['NaN Threshold', 'Replace'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After deciding on the best pre-processing method, we apply a grid search across two parameters of the Random Forest model.\n",
    "\n",
    "| Number of Estimators | Max Features       |\n",
    "|----------------------|--------------------|\n",
    "| 50                   | 10                 |\n",
    "| 100                  | 50                 |\n",
    "| 300                  | auto               |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying a Random Forest Classifier to the Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocess_data(train_df.drop('target', axis=1), scaler, nan_thresh=0.6, replace='zero')\n",
    "y = train_df['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "params = {'n_estimators': [50, 100, 300], 'max_features': [10, 50, 'auto']}\n",
    "clf = GridSearchCV(rf, params)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "grid_search_heatmap(clf.cv_results_, ['max_features', 'n_estimators'], ['Max Features', 'N Estimators'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have pre-processing method in place and a well-tuned model, we can apply gradient boosting to further increase our accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "X = preprocess_data(train_df.drop('target', axis=1), scaler, nan_thresh=0.6, replace='zero')\n",
    "y = train_df['target']\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, test_size=0.3)\n",
    "my_model = XGBClassifier()\n",
    "my_model.fit(train_X, train_y, \n",
    "             early_stopping_rounds=5, \n",
    "             eval_set=[(val_X, val_y)],\n",
    "             verbose=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocess_data(train_df.drop('target', axis=1), scaler, nan_thresh=0.6, replace='zero')\n",
    "y = train_df['target']\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, test_size=0.3)\n",
    "my_model.score(val_X, val_y)\n",
    "test_preds = my_model.predict(test_df_needed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find that the gradient boosting did not have a noticable effect, which is likely because the initial model was already performing so well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame({'Id': test_df['id'],\n",
    "                       'target': test_preds})\n",
    "output.to_csv('submission_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA of the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "X = preprocess_data(train_df.drop('target', axis=1), scaler, nan_thresh=0.6, replace='zero')\n",
    "y = train_df['target']\n",
    "X = X.drop(columns = 'id')\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, test_size=0.3)\n",
    "pca = PCA(n_components=train_X.shape[1])\n",
    "trainx_pca = pca.fit_transform(train_X)\n",
    "train_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are performing the PCA to determine the key feature and reduce the dimensionality of the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(1, 2)\n",
    "ax[0].scatter(y = pca.explained_variance_ratio_, x = range(0,len(pca.explained_variance_ratio_)) )\n",
    "ax[0].set_title('Variance')\n",
    "ax[1].scatter(y = pca.singular_values_, x = range(0,len(pca.singular_values_)) )\n",
    "ax[1].set_title('Singular')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We determined that the majority of the feature does not have a major impact on the model ability to predict failure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocess_data(train_df.drop('target', axis=1), scaler, nan_thresh=0.6, replace='zero')\n",
    "y = train_df['target']\n",
    "X = X.drop(columns = 'id')\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "pca = PCA(n_components = 5)\n",
    "trainx_pca = pca.fit_transform(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,5):\n",
    "    k = np.amax(pca.components_[:][i])\n",
    "    print(np.where(pca.components_ == k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = pca.components_ >= 0\n",
    "value = matrix[:][0]+matrix[:][1]+matrix[:][2]+matrix[:][3]\n",
    "x = np.arange(0,matrix.shape[1],1)\n",
    "x_false = x[value== False]\n",
    "\n",
    "postpac_data = np.delete(train_X,x[value== False],axis=1)\n",
    "postpac_test =  np.delete(val_X,x[value== False],axis=1)\n",
    "pca2 = PCA(n_components = 15)\n",
    "pca2.fit_transform(postpac_data)\n",
    "\n",
    "plt.scatter(y = pca2.explained_variance_ratio_, x = range(0,len(pca2.explained_variance_ratio_)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca2 = PCA(n_components = 6)\n",
    "pca2_train = pca2.fit_transform(postpac_data)\n",
    "pca2_val = pca2.transform(postpac_test)\n",
    "\n",
    "\n",
    "descision_tree_model = RandomForestRegressor(random_state=1)\n",
    "    # Fit Model\n",
    "descision_tree_model.fit(pca2_train, train_y)\n",
    "# Make validation predictions and calculate mean absolute error\n",
    "val_predictions = descision_tree_model.predict(pca2_val).astype(int)\n",
    "val_mae = mean_absolute_error(val_predictions, val_y)\n",
    "print(val_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model was able to obtain an accuracy of 98.32% while decreasing the number of features from 160 to 66. This showed that the failure model is heavily dependent on these 66 features. It also showed that the remaining 94 feature does not provide major information to the model to make a decision. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a Training and validation set to train the model base of the reliable feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Data_train[Data_train.columns[Data_train.columns != 'target']]\n",
    "X = preprocessing.normalize(X)\n",
    "y = Data_train['target']\n",
    "train_X, val_X, train_y, val_y  = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "count = np.array([(y[y==0]).count(),(y[y==1]).count()])\n",
    "objects = ('No Failure', 'Failure')\n",
    "plt.bar(np.arange(len(objects)), count, align='center', alpha=0.5, color='black')\n",
    "plt.title('No Failure to Failure count'),plt.xticks(np.arange(len(objects)), objects)\n",
    "plt.ylabel('Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our journey thought, we discovered that Random Forest Regression performed optimally in predicting equipment failer. We were also discovered that XG Boosting  Classifier did not improve over the Random Forest Regression results. The team was also able to use partial component analysis(PCA) to reduce the number of features used in the data, without significant loss inaccuracy. A possible route in the continuation of our journey is to perform statistical analysis on the obtained PCA and determine the statistical significance of the different weights. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
